---
title: "Displacement Risk Tracker"
author: "Asha Bazil, Hannah Wagner"
date: "December 15, 2020"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggcorrplot)
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(mapview)
library(RColorBrewer)
library(remotes)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
```


```{r Themes, message=FALSE, warning=FALSE}

mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black", size=12),
    plot.title = element_text(size = 13,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black", size=12),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "lightskyblue1", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
```

## Intro

This analysis aims to create a tool that can be used by city housing departments across the United States as a means of predicting and preventing potential residential displacement. We pilot this idea with the Philadelphia Division of Housing and Community Development in mind, in an effort to help the division allocate limited housing resources to vulnerable residents. 

Our method uses issuance of residential building permits as an indicator of displacement risk. Neighborhoods with significant residential construction often experience higher levels of displacement, which we define as the movement of longtime residents due to uneven distribution of home value increases. New residential construction and renovations increase home values, but also raise property taxes on nearby older homes, whose owners do not benefit from improvements themselves. This increase in cost of living can act to drive lower income residents out of the neighborhood in search of more affordable areas, which are likely further away from amenities such as public transportation, schools, and green spaces. 

This Displacement Tracker Tool works to prevent displacement in three key ways:

1 Anticipates neighborhoods where home values may increase and threaten the ability of existing residents to remain;

2 Identifies trusted community partners in each area of the city who can communicate effectively with local residents based on established trust; and

3 Estimates the benefit various policy levers, such as flip taxes or home renovation subsidies, can have on the long-time residents of each neighborhood.


Because homeowners are often rightly skeptical of communications regarding their property and its value, we strive to ensure that this information comes from an already proven and trusted source. This data-driven and community facilitated approach to displacement prevention is a new method for addressing the issue that many other cities and regions would benefit from implementing. We hope that this open-data analysis will serve as a basis for cities looking to rethink their response to displacement. 


## Data

Underlying our Displacement Tracker Tool is a model that uses a variety of data to predict the count of residential building permits across the city. The Tool also incorporates data on potential outreach partners, who are trusted organizations within communities. Most data area gathered from [OpenDataPhilly](https://www.opendataphilly.org/), the City of Philadelphia's catalog of available data in the Philadelphia region. We also use data from the U.S. Census Bureau's 2018 5-year [American Community Survey](https://www.census.gov/programs-surveys/acs) to understand information about the population such as education level and median income. The sections below describe our process for gathering and cleaning various datasets.


### Base data

To begin, we gather Philadelphia residential building permit data from 2015 through 2019 from the [Licenses and Inspections Building and Zoning Permit Dataset](https://www.opendataphilly.org/dataset/licenses-and-inspections-building-permits). These data from the Department of Licenses & Inspections provide the date, location, and a variety of ancillary information about building permits in the city. Building permits are required before the start of a specific construction activity to enlarge, repair, change, add or, or demolish a structure, and to install equipment or systems in a structure. From this dataset, we've selected only residential building permits, as we believe that residential construction is a strong primary indicator of displacement risk for longtime residents. Areas with large amounts of residential building permits may indicate an early warning sign for neighborhood changes that can increase the risk of longtime resident displacement. As renovation and construction occurs on a high density of residential properties, neighborhoods can become more expensive, experience higher real estate taxes that may burden lower income residents, and/or experience cultural shifts that may make longtime residents feel they no longer belong.^[Pew Charitable Trusts. 2016. Philadelphia's Changing Neighborhoods: Gentrificaiton and other shifts since 2000. https://www.pewtrusts.org/~/media/assets/2016/05/philadelphias_changing_neighborhoods.pdf].

Importantly, we also gather data on locations and contact information for Philadelphia [Registered Community Organizations](https://www.phila.gov/programs/registered-community-organizations-rcos/) (RCOs), which are community groups that are concerned with the physical development of their community. RCOs get advance notice of projects that will be reviewed by the Zoning Board of Adjustment or the Civic Design Review Committee; organize and conduct public meetings where community members can comment on planned developments in their neighborhood; and get notifications from the Philadelphia City Planning Commission whenever a zoning variance or special exception is requested or when development requiring Civic Design Review is proposed. We use this RCO data to identify potential trusted community partners within each neighborhood that may be able to communicate effectively with local residents based on established trust.

```{r read in base data, message=FALSE, warning=FALSE}
#residential building permit

permits <- 
  st_read("https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+permits+WHERE+permitissuedate+>=+'2015-01-01'+AND+permitissuedate+<+'2019-12-31'AND+permitdescription+=+'RESIDENTIAL+BUILDING+PERMIT'&filename=permits&format=geojson&skipfields=cartodb_id") %>% 
    st_transform('ESRI:102729') 

# ggplot() +
#   geom_sf(data = permits)

#mapview(permits)

boundary<-
st_read("http://data.phl.opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson") %>%
st_transform('ESRI:102729') %>%
st_union()

# ggplot() +
#   geom_sf(data = boundary)

rcos <-
st_read("http://data.phl.opendata.arcgis.com/datasets/efbff0359c3e43f190e8c35ce9fa71d6_0.geojson") %>%
st_transform('ESRI:102729')

```


Next, we create a geospatial dataset to help us understand the smooth variation of displacement risk across the city. This key element of our analysis is the "fishnet," a continuous grid pattern overlay in which every polygon is connected on all sides to the other polygon neighbors. This analysis uses a fishnet with 500x500 foot grid cells. We use a fishnet to treat displacement risk (presence of residential construction permits) as a phenomenon that varies continuously across space. We will use the fishnet to aggregate point-level data.

The figure below shows the count of residential building permits across the fishnet. Grid cells shown in yellow have the largest number of residential permits. These locations are primarily concentrated in the Center City and North East Philadelphia areas.

```{r fishnet, message=FALSE, warning=FALSE}

# create the fishnet

# uses grid.arrange to organize independent plots
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = boundary) +
  geom_sf(data = permits, colour="red", size=0.1, show.legend = "point") +
  labs(title= "Permits, Phil - 2010-2020")+
  mapTheme(),
ggplot() + 
  geom_sf(data = boundary, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(permits)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Permits") +
  theme(legend.position = "none")+
  mapTheme())

#Fishnet code
fishnet <- 
  st_make_grid(boundary,
               cellsize = 500, 
               square = TRUE) %>%
  .[boundary] %>%
  st_sf() %>%
  mutate(uniqueID = rownames(.))

permit_net <- 
  dplyr::select(permits) %>% #an SF point object
  mutate(countpermits = 1) %>% #giving value of one to each point
  aggregate(., fishnet, sum) %>% #aggregate points. period represents burglaries. sum number of "1" points that fall within each grid cell. aggregate is a type of spatial join. normally would do a join and them summarize, but this does both in one step. 
  mutate(countpermits = replace_na(countpermits, 0), #where there weren't any crimes
         uniqueID = rownames(.),#make into a column
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE)) #adding a random number to each grid cell for cross validation later

ggplot() +
  geom_sf(data = permit_net, aes(fill = countpermits), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Permits for the fishnet") +
  mapTheme()

```


Next we gather data on the boundaries of Philadelphia's neighborhoods. We will use neighborhood's as a unit of analysis for both cross-validation of the predictive model and to understand locations of greatest risk. 

```{r nhood data, message=FALSE, warning=FALSE}
#nhood <- st_read("/Users/ashabazil/Documents/GitHub/geo-data/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson") %>%
#st_transform(st_crs(fishnet)) 

#Should work for both of us using this link
nhood<- st_read("https://raw.githubusercontent.com/azavea/geo-data/2e0c6a9f42d862e39dcee292b851000c973e6de2/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson") %>%
st_transform(st_crs(fishnet)) 

#ggplot()+
  #geom_sf(data=nhood)+
  #mapTheme()
```

### Home Value Exploration

To further help us understand neighborhood changes that may lead to displacement risk, we gather data from the Department of Records on [Real Estate Transfers](https://www.opendataphilly.org/dataset/real-estate-transfers). The real estate transfers data shows the dates and location of property sales, deeds, mortgages, and sheriff deeds, and includes associated data, such as any realty transfer tax paid. We gathered data for 2017 and 2018, and calculated the percent change in home value in order to categorize each observation as "No Change", "Increase in Home Value", "Decrease in Home Value", or "No Answer." Because we are focused on changes in home value (and resulting increases in property taxes) as a primary mechanism for driving displacement, we wish to understand the patterns of changes in home values across the city.

In the figure below, we see locations with the greatest density of changes in home value. These locations are concentrated in the Center City area. 

```{r real estate value, message=FALSE, warning=FALSE}

#real estate transfer data
#this takes a while
rt <- 
  st_read("https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+RTT_SUMMARY+WHERE+display_date+>='2017-01-01'+AND+display_date+<=+'2018-12-31'AND+opa_account_num+!=+'NA'&format=geojson&skipfields=cartodb_id") %>% 
st_transform('ESRI:102729')

#filter for obs with values
rtt <- rt %>% 
    mutate(adjusted_fair_market_value = replace_na(adjusted_fair_market_value, 0), year = substr(display_date,1,4)) %>% 
    filter(!(adjusted_fair_market_value == 0)) %>% 
    dplyr::select(adjusted_fair_market_value, opa_account_num, year)

#split by year 
rtt_17 <- rtt %>% 
    filter(year == 2017) %>% 
    rename(value_17 = adjusted_fair_market_value) %>% 
    filter(value_17<=9878103)

rtt_18 <- rtt %>% 
    filter(year == 2018) %>% 
    rename(value_18 = adjusted_fair_market_value)


#create difference percent, difference value, and categorical variable
joined<-
  st_join(rtt_17, rtt_18, by = opa_account_num) %>% 
  mutate(difference = value_18-value_17,
         dif_cat= case_when(difference == 0 ~ "No Change", 
                            difference > 0 ~ "Increase in Home Value", 
                            difference < 0 ~ "Decrease in Home Value",
                            # anything that isn't in the above groups (i.e. NA which is No Answer) gets to be No Answer
                            TRUE ~ "No Answer"),
         dif_cat = factor(dif_cat, levels = c("Decrease in Home Value", "Increase in Home Value", "No Change", "No Answer")),
         dif_pct= (difference/value_17)*100) %>%
  filter(!(difference == is.na(.)))

#split by increase and decreased

decreasedHV <-
  joined %>% 
  filter(dif_cat == "Decrease in Home Value")

increasedHV <-
  joined %>% 
  filter(dif_cat == "Increase in Home Value")

ggplot() + 
  geom_sf(data = boundary, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(joined)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.02, bins = 50, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.50), guide = FALSE) +
  labs(title = "Home Value Difference") +
  theme(legend.position = "none")+
  mapTheme()
```


The figures below depict the increases and decreases in home value between 2017 and 2018 by percentage difference. Locations with greatest increases are generally clustered in the Center City area and locations directly to the north. Locations with greatest decrease are more widely scattered across the city. 

```{r home value exploratory plots, message=FALSE, warning=FALSE}
# plot magnitude of percentage increases and decreases
#flip color scale for decrease, filter out small decrease differences

grid.arrange(ncol=2,
  ggplot()+
    geom_sf(data = nhood, fill = "grey40") +
    geom_sf(data=increasedHV, aes(color=q5(dif_pct)),
            show.legend="point", size=1)+
    scale_color_viridis(discrete = TRUE,
                        labels=qBr(increasedHV, "dif_pct"),
                        name="Quintile\nBreaks")+
    labs(title="Home Value increases between 2017 and 2018\nby Percentage Difference")+
    mapTheme(),
  
    ggplot()+
    geom_sf(data = nhood, fill = "grey40") +
    geom_sf(data=decreasedHV, aes(color=q5(dif_pct)),
            show.legend="point", size=1)+
    scale_color_viridis(discrete = TRUE,
                        labels=qBr(decreasedHV, "dif_pct"),
                        name="Quintile\nBreaks")+
    labs(title="Home Value decreases between 2017 and 2018\nby Percentage Difference")+
    mapTheme())
  
```  


To further understand changes in home value, the figures below show the distribution of home values across the city in 2018 and 2018. The pattern remains largely the same across the city.

```{r home values plot, message=FALSE, warning=FALSE}
#plot of just homevalue
rtt_plot<-
  rtt%>%
  filter(year==2017|year==2018)

ggplot()+
    geom_sf(data = nhood, fill = "grey40") +
    geom_sf(data=rtt_plot, aes(color=q5(adjusted_fair_market_value)),
            show.legend="point", size=1)+
    scale_color_viridis(discrete = TRUE,
                        labels=qBr(rtt_plot, "adjusted_fair_market_value"),
                        name="Quintile\nBreaks")+
    facet_wrap(~year)+
    labs(title="Home Values")+
    mapTheme()

#updated to include faceted plot above, so delete this if that looks good to you.
grid.arrange(ncol=2,
  ggplot()+
    geom_sf(data = nhood, fill = "grey40") +
    geom_sf(data=rtt_17, aes(color=q5(value_17)),
            show.legend="point", size=1)+
    scale_color_viridis(discrete = TRUE,
                        labels=qBr(rtt_17, "value_17"),
                        name="Quintile\nBreaks")+
    labs(title="Home Value 2017")+
    mapTheme(),
  
   ggplot()+
    geom_sf(data = nhood, fill = "grey40") +
    geom_sf(data=rtt_18, aes(color=q5(value_18)),
            how.legend="point", size=1)+
    scale_color_viridis(discrete = TRUE,
                        labels=qBr(rtt_18, "value_18"),
                        name="Quintile\nBreaks")+
    labs(title="Home Value 2018")+
    mapTheme())
```  


The figures below show the density of locations where home values increased and decreased between 2017 and 2018. Both of these locations are concentrated in the Center City area, with a greater intensity of home value increases in that location.

```{r home value density, message=FALSE, warning=FALSE}
#denisty of homevalues in 2017 and 2018
#does this show density of greatest home values? or density of where there are home values? We have a lot of plots here so not sure if we need these - let me know what you think!
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = nhood, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(rtt_17)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.02, bins = 50, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.50), guide = FALSE) +
  labs(title = "2017") +
  theme(legend.position = "none")+
  mapTheme(),

ggplot() + 
  geom_sf(data = nhood, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(rtt_18)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "2018") +
  theme(legend.position = "none")+
  mapTheme())

#density of change in homevalues based on increasing and decreasing
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = nhood, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(increasedHV)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.02, bins = 50, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.50), guide = FALSE) +
  labs(title = "Locations where Home Values Increased, 2017-2018") +
  theme(legend.position = "none")+
  mapTheme(),

ggplot() + 
  geom_sf(data = nhood, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(decreasedHV)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Locations where Home Values Decreased, 2017-2018") +
  theme(legend.position = "none")+
  mapTheme())
```


Finally, the histogram below shows the distribution of percentage changes in home value from 2017 to 2018. From this plot, we can see that...

I changed the dif_pct above and this changed. let's discuss.
remove?
```{r home value histogram, message=FALSE, warning=FALSE}
#histogram of change in home value, kind of ugly
joined %>%
  tibble::rowid_to_column(., "ID") %>%
  dplyr::filter(., !(dif_cat %in% c("No Change", "No Answer"))) %>%
  dplyr::select(difference,dif_pct, ID) %>%
  ggplot(aes(x = dif_pct)) +
  geom_density(  fill="#1f2a59", color="#e9ecef") +
  scale_x_continuous(limits = c(-4.5,1.4))+
  scale_y_continuous(limits = c(0,1.25)) +
  labs(x = "Percentage Change in Value", y = "Responses",
       title = "Percentage Change in Value, 2017 and 2018") +
  plotTheme() + theme(legend.position = "bottom", axis.text.x = element_text(size = 8))

```


### 311 and Census Data

We also gathered data on [311 Service and Information Requests](https://www.opendataphilly.org/dataset/311-service-and-information-requests) to included in our predictive model. These data represents all service and information requests submitted to the Philly311 via the 311 mobile application, calls, walk-ins, emails, the 311 website, or social media. From the 311 data, we gathered data from 2015 to 2019 on locations of Sanitation & Dumpster Violations, locations of Dangerous Building Reports, and locations of Vacant Lot Reports. We use these data as variables in the model to help predict locations of residential building permits.

The figures below show the density of locations of these reports and violations, which are distributed across the city. 

```{r 311 data, message=FALSE, warning=FALSE}
#https://cityofphiladelphia.github.io/carto-api-explorer/#public_cases_fc

# Sanitation Data
sanitation<-
  st_read("https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+public_cases_fc+WHERE+service_name+=+'Sanitation+/+Dumpster+Violation'OR+service_name+=+'Illegal+Dumping'+AND+requested_datetime+>=+'2015-01-01'+AND+requested_datetime+<+'2019-12-31'&filename=sanitation&format=geojson&skipfields=cartodb_id") %>%
    mutate(year = substr(requested_datetime,1,4)) %>% 
    #filter(year %in% c("2020")) %>%
    dplyr::select(Y = lat, X = lon) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Sanitation")

# Service Data
service<-
  st_read("https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+public_cases_fc+WHERE+service_name+=+'Building+Dangerous'+AND+requested_datetime+>=+'2015-01-01'+AND+requested_datetime+<+'2019-12-31'&filename=service&format=geojson&skipfields=cartodb_id") %>%
    mutate(year = substr(requested_datetime,1,4)) %>% 
    dplyr::select(Y = lat, X = lon) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Service")


# Vacant Lot Data
vacant<-
  st_read("https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+public_cases_fc+WHERE+service_name+=+'Vacant+House+or+Commercial'+AND+requested_datetime+>=+'2015-01-01'+AND+requested_datetime+<+'2019-12-31'&filename=vacant&format=geojson&skipfields=cartodb_id") %>%
    mutate(year = substr(requested_datetime,1,4)) %>% 
    dplyr::select(Y = lat, X = lon) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Vacant")


grid.arrange(ncol = 3,
  ggplot() + geom_sf(data = boundary, fill = "grey40") +
      stat_density2d(data = data.frame(st_coordinates(sanitation)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
      scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
      scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
      labs(title = "Density of Sanitation Violations") +
      mapTheme()+
      theme(legend.position = "none"),
  ggplot() + geom_sf(data = boundary, fill = "grey40") +
      stat_density2d(data = data.frame(st_coordinates(service)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
      scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
      scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
      labs(title = "Density of Dangerous Building Reports") +
      mapTheme()+
      theme(legend.position = "none"),
  ggplot() + geom_sf(data = boundary, fill = "grey40") +
      stat_density2d(data = data.frame(st_coordinates(vacant)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
      scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
      scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
      labs(title = "Density of Vacant Lots") +
      mapTheme()+
      theme(legend.position = "none"))

```


Finally, we gathered data from the U.S. Census Bureau 2018 5-year American Community Survey (ACS) at the census tract level on median household income, education level, and moving dates. We used these data to calculate the following variables for inclusion in the predictive model:
*Percent of Voting Age Population with the following Education levels:
 +No High School Degree
 +High School Degree
 +Some College Education
 +Associate's Degree
 +Bachelor's Degree
 +Graduate or Professional Degree
*Percent of Residents in Owner-Occupied Housing
*Percent of Residents in Renter-Occupied Housing
*Percent of Residents who Moved into Owner-Occupied Housing:
 +Before 2010
 +2010 to 2014
 +2015 to 2018
*Percent of Residents who Moved into Renter-Occupied Housing:
 +Before 2010
 +2010 to 2014
 +2015 to 2018

As described in further detail below, we used a selection of these variables within our predictive model as indicators of residential building permit locations.

```{r ACS Data, message=FALSE, warning=FALSE}
census_api_key("337be6633f769979b1dfc56e5071279d780c2090", overwrite = TRUE)

dd18_5 <- load_variables(year = 2018, dataset = "acs5", cache = TRUE)

variables=c(Median_HHInc="B19013_001",
            VotingAgePop="B29002_001", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: TOTAL
            HS_LessThan9Grade="B29002_002", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: Less than 9th grade
            HS_9to12Grade="B29002_003", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: 9th to 12th grade, no diploma
            HS="B29002_004", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: High school graduate (includes equivalency)
            SomeCollege="B29002_005", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: Some college, no degree
            Associate="B29002_006", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: Associate's degree
            Bach="B29002_007", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: Bachelor's degree
            GradProf="B29002_008", #CITIZEN, VOTING-AGE POPULATION BY EDUCATIONAL ATTAINMENT: Graduate or professional degree
            Pop_occHousing="B25026_001", #Total population in occupied housing units
            Pop_OwnOcc="B25026_002", #Total population in occupied housing units!!Owner occupied
            Pop_Own2017later="B25026_003", #Total population in occupied housing units!!Owner occupied!!Moved in 2017 or later
            Pop_Own2015to2016="B25026_004", #Total population in occupied housing units!!Owner occupied!!Moved in 2015 to 2016
            Pop_Own2010to2014="B25026_005", #Total population in occupied housing units!!Owner occupied!!Moved in 2010 to 2014
            Pop_Own2000to2009="B25026_006", #Total population in occupied housing units!!Owner occupied!!Moved in 2000 to 2009
            Pop_Own1990to1999="B25026_007", #Total population in occupied housing units!!Owner occupied!!Moved in 1990 to 1999
            Pop_Own1989earlier="B25026_008", #Total population in occupied housing units!!Owner occupied!!Moved in 1989 or earlier
            Pop_RentOcc="B25026_009", #Total population in occupied housing units!!Renter occupied
            Pop_Rent2017later="B25026_010", #Total population in occupied housing units!!Renter occupied!!Moved in 2017 or later
            Pop_Rent2015to2016="B25026_011", #Total population in occupied housing units!!Renter occupied!!Moved in 2015 to 2016
            Pop_Rent2010to2014="B25026_012", #Total population in occupied housing units!!Renter occupied!!Moved in 2010 to 2014
            Pop_Rent2000to2009="B25026_013", #Total population in occupied housing units!!Renter occupied!!Moved in 2000 to 2009
            Pop_Rent1990to1999="B25026_014", #Total population in occupied housing units!!Renter occupied!!Moved in 1990 to 1999
            Pop_Rent1989earlier="B25026_015") #Total population in occupied housing units!!Renter occupied!!Moved in 1989 or earlier

ACS_2018 <- get_acs(geography = "tract",
                           state = 42,
                           county= 101,
                           variables = variables,
                           year = 2018,
                           geometry=T)%>%
  st_transform('ESRI:102729')  %>% 
  dplyr::select(variable, estimate, GEOID) %>%
  spread(variable, estimate) %>%
  mutate(percent_NoHS= ifelse(VotingAgePop>0,((HS_LessThan9Grade+HS_9to12Grade) / VotingAgePop),0),
         percent_HS= ifelse(VotingAgePop>0, HS/ VotingAgePop,0),
         percent_SomeCollege= ifelse(VotingAgePop>0,SomeCollege / VotingAgePop,0),
         percent_assoc = ifelse(VotingAgePop>0,Associate / VotingAgePop,0),
         percent_bach = ifelse(VotingAgePop>0,Bach / VotingAgePop,0),
         percent_GradProf = ifelse(VotingAgePop>0,GradProf / VotingAgePop,0),
         percent_ownOcc= ifelse(Pop_occHousing>0,Pop_OwnOcc / Pop_occHousing,0),
         percent_rentOcc = ifelse(Pop_occHousing>0,Pop_RentOcc / Pop_occHousing,0),
         percent_Own_Pre2010 = ifelse(Pop_occHousing>0,
                                      ((Pop_Own1989earlier + Pop_Own1990to1999 + Pop_Own2000to2009) / Pop_occHousing),0),
         percent_Own_2010to2014 = ifelse(Pop_occHousing>0,Pop_Own2010to2014 / Pop_occHousing,0),
         percent_Own_2015to2018 = ifelse(Pop_occHousing>0,((Pop_Own2015to2016 + Pop_Own2017later) / Pop_occHousing),0),
         percent_Rent_Pre2010 = ifelse(Pop_occHousing>0,
                                       ((Pop_Rent1989earlier + Pop_Rent1990to1999 + Pop_Rent2000to2009) / Pop_occHousing),0),
         percent_Rent_2010to2014 = ifelse(Pop_occHousing>0,Pop_Rent2010to2014 / Pop_occHousing,0),
         percent_Rent_2015to2018 = ifelse(Pop_occHousing>0,
                                          ((Pop_Rent2015to2016 + Pop_Rent2017later) / Pop_occHousing),0))%>%
 dplyr::select(Median_HHInc, percent_NoHS, percent_HS, percent_SomeCollege, percent_assoc, percent_bach, percent_GradProf, 
         percent_ownOcc, percent_rentOcc, percent_Own_Pre2010, percent_Own_2010to2014, percent_Own_2015to2018, 
         percent_Rent_Pre2010, percent_Rent_2010to2014,   percent_Rent_2015to2018)%>%
  mutate(Median_HHInc = replace_na(Median_HHInc, 0),
         percent_NoHS = replace_na(percent_NoHS,0),
         percent_HS= replace_na(percent_HS,0),
         percent_SomeCollege= replace_na(percent_SomeCollege,0),
         percent_assoc= replace_na(percent_assoc,0),
         percent_bach= replace_na(percent_bach,0),
         percent_GradProf= replace_na(percent_GradProf,0),
         percent_ownOcc= replace_na(percent_ownOcc,0),
         percent_rentOcc= replace_na(percent_rentOcc,0),
         percent_Own_Pre2010= replace_na(percent_Own_Pre2010,0),
         percent_Own_2010to2014= replace_na(percent_Own_2010to2014,0),
         percent_Own_2015to2018= replace_na(percent_Own_2015to2018,0),
         percent_Rent_Pre2010= replace_na(percent_Rent_Pre2010,0),
         percent_Rent_2010to2014= replace_na(percent_Rent_2010to2014,0),
         percent_Rent_2015to2018= replace_na(percent_Rent_2015to2018,0))
  
```


The figures below show the distribution of residents in owner-occupied housing who moved in before 2010 (left), and between 2015 and 2018 (right). From these maps we can see that some locations have a greater percentage of new homeowners (yellow areas on the map at right), including the Point Breeze and Northern Liberties Neighborhoods.

```{r ACS Plots, message=FALSE, warning=FALSE}
ACS_2018_plot<-
  ACS_2018%>%
  mutate(percent_Own_Pre2010_per=percent_Own_Pre2010*100)%>%
  mutate(percent_Own_2015to2018_per=percent_Own_2015to2018*100)%>%
  mutate(percent_Rent_2015to2018_per=percent_Rent_2015to2018*100)

grid.arrange(ncol=2,
ggplot()+
  geom_sf(data=ACS_2018_plot, aes(fill=q5(percent_Own_Pre2010_per)))+
  scale_fill_viridis(discrete = TRUE,
                    labels = qBr(ACS_2018_plot, "percent_Own_Pre2010_per"),
                    name = "Owned Pre-2010\n(Quintile Breaks)") +
  labs(title = "Percentage of Residents in Owner-Occupied Housing: \nMoved in Before 2010") +
  mapTheme(),
ggplot()+
  geom_sf(data=ACS_2018_plot, aes(fill=q5(percent_Own_2015to2018_per)))+
  scale_fill_viridis(discrete = TRUE,
                    labels = qBr(ACS_2018_plot, "percent_Own_2015to2018_per"),
                    name = "Quintile Breaks") +
  labs(title = "Percentage of Residents in Owner-Occupied Housing: \nMoved in Between 2015 and 2018") +
  mapTheme())
  
```


### Data Wrangling 

After collecting the variety of data described above to serve as indicators of residential permits, we aggregated all data to our previously created fishnet. For point data (e.g., sanitation violations, vacant lot locations), we count the number of incidents within each grid cell. For census data (e.g., median household income), we join the census data values from the census tract where the centroid of each grid cell is located.

```{r Putting variables into fishnet, message=FALSE, warning=FALSE, include=TRUE}

#put other data into fishnet. 
vars_net <- 
  rbind(sanitation, service, vacant) %>%
  st_join(., fishnet, join=st_within) %>% #if point is within this polygon, assign the polygon id to this point. then get it into the unit of grid polygons
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>% #group by unique id and the type of variable, in this case just one cars
  summarize(count = n()) %>% #counting each point per grid cell
  full_join(fishnet, by = "uniqueID") %>%
  spread(Legend, count, fill=0) %>%
  st_sf() %>%
  dplyr::select(-`<NA>`) %>%
  na.omit() %>%
  ungroup()

```

```{r Add census data to fishnet, message=FALSE, warning=FALSE, include=TRUE}
vars_net<-
  vars_net%>%
  st_centroid()%>%
  st_join(ACS_2018)%>%
  na.omit()

```


## Spatial processes

### Nearest Neighbor Prediction Factors by Fishnet

Next we creates average nearest neighbor features for each risk factor by converting the grid cells to centroid points and then measuring the distance to 3 risk factor points.

```{r nn_function}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <-
    as.matrix(measureFrom)
  measureTo_Matrix <-
    as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
    output <-
      as.data.frame(nn) %>%
      rownames_to_column(var = "thisPoint") %>%
      gather(points, point_distance, V1:ncol(.)) %>%
      arrange(as.numeric(thisPoint)) %>%
      group_by(thisPoint) %>%
      summarize(pointDistance = mean(point_distance)) %>%
      arrange(as.numeric(thisPoint)) %>% 
      dplyr::select(-thisPoint) %>%
      pull()
  
  return(output)  
}

```

```{r NN function for predictors, message=FALSE, warning=FALSE, include=TRUE}
st_c <- st_coordinates
st_coid <- st_centroid

vars_net <-
  vars_net %>%
    mutate(
      Sanitation.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(sanitation),3),
      Service.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(service),3),
      Vacant.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(vacant),3))


```

### Creating Distance to Center City as a variable

We next calculate the distance to downtown Philadelphia (Center City) and add the risk factor to the fishnet.

```{r Measuring distance to one point, message=FALSE, warning=FALSE, include=TRUE}
ccPoint <-
  filter(nhood, name == "CENTER_CITY") %>%
  st_centroid()

vars_net$ccDistance =
  st_distance(st_centroid(vars_net),ccPoint) %>%
  as.numeric() 

```


### Variable Plots
The figures below depict a selection of risk factors mapped to the fishnet. The variety of spatial distributions across these maps indicate that the risk factors illustrate different spatial processes. For example, locations with high concentrations of residents with a Bachelor's degree are concentrated in the Center City and Northwest Philadelphia areas, while distance to the nearest three sanitation violations are distributed roughly evently across the city. 

```{r feature plots, message=FALSE, warning=FALSE,}
grid.arrange(ncol=3,
  ggplot()+
    geom_sf(data=vars_net, aes(color=Median_HHInc))+
    scale_color_viridis()+
    labs(title="Median Household Income")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_HS))+
    scale_color_viridis()+
    labs(title="Percent of Voting-Age Population \nwithout a High School Degree")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_bach))+
    scale_color_viridis()+
    labs(title="Percent of Voting-Age Population \nwith a Bachelors Degree")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_ownOcc))+
    scale_color_viridis()+
    labs(title="Percent of the Population Living \nin Owner-Occupied Housing")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_Own_Pre2010))+
    scale_color_viridis()+
    labs(title="Percent of the Population Living in \nOwner-Occupied Housing: Moved in Before 2010")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_Own_2015to2018))+
    scale_color_viridis()+
    labs(title="Percent of the Population Living in \nOwner-Occupied Housing: Moved in Between 2015-2018")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_Rent_Pre2010))+
    scale_color_viridis()+
    labs(title="Percent of the Population Living in \nRenter-Occupied Housing: Moved in Before 2010")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=percent_Own_2015to2018))+
    scale_color_viridis()+
    labs(title="Percent of the Population Living in \nRenter-Occupied Housing: Moved in Between 2015-2018")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=Sanitation.nn))+
    scale_color_viridis()+
    labs(title="Distance to Nearest 3 Saniation Violations")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=Service.nn))+
    scale_color_viridis()+
    labs(title="Distance to Nearest 3 Service Requests")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=Vacant.nn))+
    scale_color_viridis()+
    labs(title="Distance to Nearest 3 Vacant Lots")+
    mapTheme(),
  ggplot()+
    geom_sf(data=vars_net, aes(color=ccDistance))+
    scale_color_viridis()+
    labs(title="Distance to Center City")+
    mapTheme())
            
```


### Create final net
Finally, we perform a join to combine the permit data with the risk factor data and join neighborhoods to the final net. 

```{r doing spatial join, message=FALSE, warning=FALSE, include=TRUE}
## important to drop the geometry from joining features
final_net <-
  left_join(permit_net, st_drop_geometry(vars_net), by="uniqueID") 

```


```{r creating final fish net, message=FALSE, warning=FALSE, include=TRUE}
#polygon to polygon joins are hard. 

final_net <-
  st_centroid(final_net) %>% #take the centroid of the fishnet
    st_join(dplyr::select(nhood, name), by = "uniqueID") %>% #spatially join those withinthe nhood polygons nd polict districs. ie assign the neighborhood to the fishnet id for whichever nhood the fishnet centroid falls into
    #st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%  #get the fishnet back in to get the polygons. drop the geom to do the left join and then being it back in
      st_sf() %>%
  na.omit()

# for live demo
# mapview::mapview(final_net, zcol = "District")

```


## Modeling Approach

Describe modeling approach

### Plots of Local Moran's I for fishnet grid cells

```{r Spatial process of theft, message=FALSE, warning=FALSE, include=TRUE}
## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE) #polygons into neighborhood which gives us list of weights for which neighbors it has. creting a netowkr graph of one grid to all others.
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)
```

```{r local Morans I, message=FALSE, warning=FALSE, include=TRUE}
final_net.localMorans <- 
  cbind(
    as.data.frame(localmoran(final_net$countpermits, final_net.weights)),
    as.data.frame(final_net)) %>% 
    st_sf() %>%
      dplyr::select(Permit_Count = countpermits, 
                    Local_Morans_I = Ii, 
                    P_Value = `Pr(z > 0)`) %>%
      mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
      gather(Variable, Value, -geometry)
  
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Permit"))
```

### Distance to Hot spot

```{r calc distance to hot spot, message=FALSE, warning=FALSE, include=TRUE}
# generates warning from NN
# final_net <- final_net %>% 
#   mutate(abandoned.isSig = 
#            ifelse(local_morans[,5] <= 0.001, 1, 0)) %>% #how close each grid cell is to a sig hotspot
#   mutate(abandoned.isSig.dist = 
#            nn_function(st_c(st_coid(final_net)),
#                        st_c(st_coid(filter(final_net, abandoned.isSig == 1))),
#                        k = 1))

final_net <-
  final_net %>% 
  mutate(permit.isSig = 
           ifelse(localmoran(final_net$countpermits, 
                             final_net.weights)[,5] <= 0.0000001, 1, 0)) %>% #does this need to changed?
  mutate(permit.isSig.dist = 
           nn_function(st_coordinates(st_centroid(final_net)),
                       st_coordinates(st_centroid(
                         filter(final_net, permit.isSig == 1))), 1))

ggplot() +
      geom_sf(data = final_net, aes(fill=permit.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Permit NN Distance") +
      mapTheme()

## What does k = 1 represent? the distance to my closest significant hot spot. Want the biggest number when we're close to a hot spot. Exposure to closest one.  Can we plot this?
```


### Correlation Plot

```{r correlation tests, fig.height=15, fig.width=15, message=FALSE, warning=FALSE, include=TRUE}
# correlation.long <-
#   st_drop_geometry(final_net) %>%
#     dplyr::select(-uniqueID, -cvID, -name,-ccDistance) %>%
#     gather(Variable, Value, -countpermits)

correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(.,-Sanitation, -Vacant, -Service, -cvID, -percent_assoc,-percent_Own_2010to2014, -percent_Rent_2010to2014, -percent_NoHS, -percent_SomeCollege,-permit.isSig, -percent_GradProf, -percent_rentOcc, -ccDistance) %>%
    gather(Variable, Value, -countpermits)

# correlation.cor <-
#   correlation.long %>%
#     group_by(Variable) %>%
#     summarize(correlation = cor(Value, countpermits, use = "complete.obs"))
#     
# ggplot(correlation.long, aes(Value, countpermits)) +
#   geom_point(size = 0.1) +
#   geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
#             x=-Inf, y=Inf) +
#   geom_smooth(method = "lm", se = FALSE, colour = "black") +
#   facet_wrap(~Variable, ncol = 2, scales = "free") +
#   labs(title = "Permit count as a function of risk factors") +
#   plotTheme()



regVars <- 
  #final_net %>%
  select_if(st_drop_geometry(final_net), is.numeric) %>%
  dplyr::select(.,-Sanitation, -Vacant, -Service, -cvID, -percent_assoc,-percent_Own_2010to2014, -percent_Rent_2010to2014, -percent_NoHS, -percent_SomeCollege,-permit.isSig, -percent_GradProf, -percent_rentOcc) %>%
  na.omit()

ggcorrplot(
  round(cor(regVars), 1), 
  p.mat = cor_pmat(regVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables")

# colNameTbl <-
# colnames(regVars)


```



### Linear regression

We create two sets of independent variables -- one using the count variables and one using the nearest neighbor variables, including our newly created variables for distance to a significant theft hot spot. 

```{r PR, message=FALSE, warning=FALSE, include=TRUE}

reg.vars <- c("Sanitation.nn", "Service.nn", "Vacant.nn","ccDistance", "Median_HHInc", "percent_HS", "percent_bach","percent_ownOcc", "percent_Own_Pre2010", "percent_Own_2015to2018","percent_Rent_Pre2010", "percent_Rent_2015to2018")

reg.ss.vars <- c("Sanitation.nn", "Service.nn", "Vacant.nn","ccDistance", "Median_HHInc", "percent_HS", "percent_bach","percent_ownOcc", "percent_Own_Pre2010", "percent_Own_2015to2018","percent_Rent_Pre2010", "percent_Rent_2015to2018","permit.isSig", "permit.isSig.dist")
```


```{r Crossvalidation and histogram of theft, message=FALSE, warning=FALSE, include=TRUE}
crossValidate <- function(dataset, id, dependentVariable, indVariables) {

allPredictions <- data.frame()
cvID_list <- unique(dataset[[id]])

for (i in cvID_list) {

  thisFold <- i
  cat("This hold out fold is", thisFold, "\n")

  fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  
  regression <-
    glm(countpermits ~ ., family = "poisson",
      data = fold.train %>% 
      dplyr::select(-geometry, -id))
  
  thisPrediction <- 
    mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
    
  allPredictions <-
    rbind(allPredictions, thisPrediction)
    
  }
  return(st_sf(allPredictions))
}

#hist(final_net$countpermits, breaks=5, xlim=c(0,5))

# final_net %>% 
# ggplot(aes(x = countpermits)) +
#     geom_density(fill="#1f2a59", color="#e9ecef") +
#     scale_x_continuous(limits = c(0,10))+
#     scale_y_continuous(limits = c(0,2)) +
#   labs(x = "Count of permits across grid cells", y = "Responses",
#          title = "Percentage Change in Monthly Income, January 2019 and 2020") +
#     plotTheme() + theme(legend.position = "bottom", axis.text.x = element_text(size = 8))



# fn_group<-
# final_net %>% 
#   mutate(countpermits = case_when(countpermits = 0 ~ "0", 
#                                   countpermits >= 1 | countpermits <5 ~ "1-5",
#                                   countpermits >= 5 | countpermits <=10 ~ "5-10",
#                                   TRUE ~ countpermits),
#  countpermits = factor(countpermits, levels = c("0", "1-5",
#                                                     "5-10"))) %>%
#   group_by(countpermits) %>% 
#   summarise(count = n()) %>% 
#   mutate(pct = round((count/sum(count)) * 100,2)) %>% 
#   ggplot() + 
#     geom_bar(aes(moved_past3Yr, pct), fill = "#1f2a59", stat = "identity") +
#     labs(x = "", y = "Percent",
#          title = "Number of times moved in the past 3 years") +
#     scale_y_continuous(limits = c(0,100)) +
#     plotTheme()

```

In this histogram we see that in most of the grid cells, the count of thefts is 0-1. This provides justification for using the Poisson regression model which is more suited this kind of data distribution. 

## Cross validation methods

We cross validate four different regressions. Two perform random k-fold cross validation - one using the simple risk factors and one adding the distance to significant hotspots variable. Two others perform LOGO-CV based on the neighborhood name - again,- one using the simple risk factors and one adding the distance to significant hotspots variable.

```{r CV on four regressions, message=FALSE, warning=FALSE, include=TRUE, results=FALSE}
reg.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countpermits",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countpermits, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countpermits",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countpermits, Prediction, geometry)

reg.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countpermits",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = name, countpermits, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countpermits",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countpermits, Prediction, geometry)
```

```{r calc errors of 4 regressions, message=FALSE, warning=FALSE, include=TRUE}
reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countpermits,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countpermits,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countpermits,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countpermits,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf() 

```

```{r plot errors, message=FALSE, warning=FALSE, include=TRUE}
error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countpermits, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count") 
```


```{r permit error magnitude, message=FALSE, warning=FALSE, include=TRUE}
error_by_reg_and_fold %>%
  filter(str_detect(Regression, "LOGO")) %>%
  ggplot() +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Permit errors by LOGO-CV Regression") +
    mapTheme() + theme(legend.position="bottom")

```


```{r mae table, message=FALSE, warning=FALSE, include=TRUE}
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable(caption = "MAE by regression") %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "#FDE725FF") %>%
    row_spec(4, color = "black", background = "#FDE725FF") 

mean(final_net$countpermits)
```

```{r pred v obs, message=FALSE, warning=FALSE, include=TRUE}
st_drop_geometry(reg.summary) %>%
  group_by(Regression) %>%
    mutate(Permit_Decile = ntile(countpermits, 10)) %>%
  group_by(Regression, Permit_Decile) %>%
    summarize(meanObserved = mean(countpermits, na.rm=T),
              meanPrediction = mean(Prediction, na.rm=T)) %>%
    gather(Variable, Value, -Regression, -Permit_Decile) %>%          
    ggplot(aes(Permit_Decile, Value, shape = Variable)) +
      geom_point(size = 2) + geom_path(aes(group = Permit_Decile), colour = "black") +
      scale_shape_manual(values = c(2, 17)) +
      facet_wrap(~Regression) + xlim(0,10) +
      labs(title = "Predicted and observed permit by observed permit decile")

```

## Risk Map and Results

Provide additional maps and data visualizations to show that your model is usefu
NOTE: I added another risk category here per Ken's comment during our presentation
```{r for risk prediction, message=FALSE, warning=FALSE, include=TRUE}
permit_risk_sf <-
  filter(reg.summary, Regression == "Spatial LOGO-CV: Spatial Process") %>%
  mutate(label = "Risk Predictions",
         Risk_Category = ntile(Prediction, 100),
         Risk_Category = case_when(
           Risk_Category >= 98 ~ "98% to 100%",
           Risk_Category >= 90 & Risk_Category <= 97 ~ "90% to 97%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) 
# %>%
#   cbind(
#     aggregate(
#       dplyr::select(theft18) %>% mutate(theftCount = 1), ., sum) %>%
#       mutate(theftCount = replace_na(theftCount, 0))) %>%
#   dplyr::select(label,Risk_Category, theftCount)

# permit_risk_sf_nh_count <-
#   permit_risk_sf %>%
#   dplyr::select(cvID, countpermits, Risk_Category) %>%
#   st_drop_geometry() %>%
#   group_by(cvID) %>%
#   summarise(Predicted_Permits=sum(countpermits)) %>%
#   dplyr::filter(., Predicted_Permits>180) %>%
#   arrange(.,-Predicted_Permits) %>%
#   rename(Neighborhood = cvID) %>%
#   ggplot() +
#   geom_bar(aes(x=reorder(Neighborhood, -Predicted_Permits), Predicted_Permits), fill = "#1f2a59", stat = "identity") +
#   labs(x = "Neighborhood",
#        title = "Top 10 Neighborhoods by Predicted Permits") +
#   #scale_y_continuous(limits = c(0,100)) +
#   plotTheme()

#does this plot draw?
permit_risk_sf_nh_risk <-
  permit_risk_sf %>%
  dplyr::select(cvID, Risk_Category, countpermits) %>%
  dplyr::filter(., Risk_Category =="98% to 100%") %>%
  st_drop_geometry() %>%
  group_by(cvID) %>%
  summarise(Predicted_Permits=sum(countpermits)) %>%
  dplyr::filter(., Predicted_Permits>150) %>%
  arrange(.,-Predicted_Permits) %>%
  rename(Neighborhood = cvID) %>%
  ggplot() +
  geom_bar(aes(x=reorder(Neighborhood, -Predicted_Permits), Predicted_Permits), fill = "#1f2a59", stat = "identity") +
  labs(x = "Neighborhood",
       title = "Neighborhoods with Predicted Permit Risk between 90-100%") +
  #scale_y_continuous(limits = c(0,100)) +
  plotTheme()



```


```{r Risk category,message=FALSE, warning=FALSE, include=TRUE}
permit_risk_sf %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data=nhood, fill = "transparent") +
    #geom_sf(data = sample_n(cvID, 300), size = .5, colour = "black") +
    #facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Risk Predictions",
         subtitle="Residential Permit Predictions") +
    mapTheme()
```




## How the Analysis meets the use case and what we could do to make the analysis better


As part of our analysis, we collected data on Registered Community Organizations (RCOs) in Philadelphia, including the RCO boundaries and primary contact information. We have matched the RCOs with Philadelphia neighborhoods and provided a table of each RCO that makes the contact information readily available. We intend this information to complement the results from our predictive analysis: as neighborhoods are identified as at risk to displacement, staff from the City may wish to contact trusted organizations in that location in order to begin a process to support longtime residents. 

```{r join RCOs to neighborhoods}
nhood_name<- nhood%>% dplyr::select(name)%>%
  rename(Neighborhood=name)
  
rcos_final<-
  st_centroid(rcos)%>%
  st_join(nhood_name)%>%
  dplyr::select(ORGANIZATION_NAME, ORGANIZATION_ADDRESS, PRIMARY_NAME, PRIMARY_ADDRESS, PRIMARY_EMAIL, PRIMARY_PHONE, Neighborhood)%>%
  arrange(Neighborhood)

rcos_final<-rcos_final[c(7, 1, 2, 3, 4, 5, 6, 8)]

st_drop_geometry(rcos_final) %>%
  kable(caption = "Registered Community Organizations by Neighborhood")%>%
    kable_styling("striped", full_width = F)%>%
  scroll_box(height = "300px")
```
